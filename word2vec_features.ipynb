{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *word2vec* feature extraction and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this nodebook are results from *word2vec* feature models while working with the original and lemmatized sentences, and comments. Catalan language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,nltk,re,numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pre-trained *word2vec* that was trained on Wikipedia corpus with dimension 100. The process of pre-training these models is described in notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_word2vec = Word2Vec.load('w2v_models/es_word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_word2vec = Word2Vec.load('w2v_models/ca_word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported file *get_train_test.py*. This file contains 3 functions:\n",
    "\n",
    "* **get_train_test(k=1,lemmatize=False,POS=False)**\n",
    "\n",
    "Reads data from *txt* files. Returns two arrays of tuples (train and test), with sentences and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "*lemmatize* - if *True* returns word lemmas\n",
    "\n",
    "*POS* - if *True* reurns words in form \"*lemma_POStag*\"\n",
    "\n",
    "* **get_train_test_comments(k=1)**\n",
    "\n",
    "Reads data from *MongoDB* (as sentence order in comments is saved there). Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "* **get_english_train_test(k=1)**\n",
    "\n",
    "Reads data from pre-created *txt* files with sentences translated to English. Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "\n",
    "For all the functions train-test split is 3/4 to 1/4, selection order depending on parameter *k*.\n",
    "\n",
    "*k* - takes values 1 to 4 - changes the selection of train-test split (used for cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(text,remove_stopwords=False,repeat=False):\n",
    "    if remove_stopwords == True:\n",
    "        #with open(\"es_stopwords.txt\") as f:\n",
    "        #    es_stopwords = f.readlines()\n",
    "        #es_stopwords = [x.strip() for x in es_stopwords] \n",
    "        es_stopwords = set(stopwords.words(\"spanish\"))\n",
    "        for stopword in es_stopwords:\n",
    "            text = re.sub(stopword, '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    punctuation = ['.',',','%','&','\\'','/','+','!']\n",
    "    rx = '[' + re.escape(''.join(punctuation)) + ']'\n",
    "    text = re.sub(rx, '', text)\n",
    "    if repeat:\n",
    "        tokens = nltk.wordpunct_tokenize(text)\n",
    "    else:\n",
    "        tokens = sorted(set(nltk.wordpunct_tokenize(text)))\n",
    "    remove_from_vocabulary = ['-',')','(','(?)','1','=','[',']','][',':','<','>',';',':)','?']\n",
    "    for i in remove_from_vocabulary:\n",
    "        if i in tokens:\n",
    "            tokens.remove(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = get_word_list(text,remove_stopwords=False,repeat=True)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts each word to word2vec vector and then averages all vectors to get averaged word2vec representation of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_es(sentence):\n",
    "    sentence_words = tokenize(sentence)\n",
    "    words = []\n",
    "    for word in sentence_words:\n",
    "        if word in es_word2vec.wv.vocab:\n",
    "            v = es_word2vec.wv[word]\n",
    "            words.append(v)\n",
    "    vect = np.mean(words,axis=0)\n",
    "    return vect\n",
    "\n",
    "def w2v_ca(sentence):\n",
    "    sentence_words = tokenize(sentence)\n",
    "    words = []\n",
    "    for word in sentence_words:\n",
    "        if word in ca_word2vec.wv.vocab:\n",
    "            v = ca_word2vec.wv[word]\n",
    "            words.append(v)\n",
    "    vect = np.mean(words,axis=0)\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function created averaged word2vec feature vectors.\n",
    "\n",
    "tf_idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_train_test_features(language=\"cat\",tf_idf=False,full_comments=False,k=1):\n",
    "    #if full_comments:\n",
    "    #    train,test = get_train_test.get_train_test_comments(k=k,language=language)\n",
    "    #else:\n",
    "    #    train,test = get_train_test.get_train_test(k=k,language=language)\n",
    "    train,test = get_train_test.get_train_test(k,lemmatize=True,language=language)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        vect = w2v_ca(sentence[0])\n",
    "        if not np.isnan(np.sum(vect)): ## check that it is not nan\n",
    "            X_train.append(vect)\n",
    "            y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        vect = w2v_ca(sentence[0])\n",
    "        if not np.isnan(np.sum(vect)): ## check that it is not nan\n",
    "            X_test.append(vect)\n",
    "            y_test.append(sentence[1])\n",
    "    if tf_idf == True:\n",
    "        transformer = TfidfTransformer(smooth_idf=False)\n",
    "        X_train = transformer.fit_transform(X_train).toarray()\n",
    "        X_test = transformer.transform(X_test).toarray()\n",
    "    return X_train,y_train,np.array(X_test),y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, Catalan, sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [4]\n",
    "random_states = [0,1,2,4,5,42,50,60,70,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *word2vec* features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2193 instances, test on 729 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec features, sentences\n",
      "SVM accuracy:  0.3901960784313726\n",
      "Logistic regression accuracy:  0.5490196078431373\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.05069124, 0.94930876],\n",
       "       [0.        , 0.25255102, 0.74744898],\n",
       "       [0.        , 0.20952381, 0.79047619]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *word2vec* + tf-idf features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2193 instances, test on 729 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,tf_idf=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec + tf-idf features, sentences\n",
      "SVM accuracy:  0.6651260504201681\n",
      "Logistic regression accuracy:  0.6680672268907563\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec + tf-idf features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47004608, 0.52534562, 0.00460829],\n",
       "       [0.05612245, 0.94132653, 0.00255102],\n",
       "       [0.1047619 , 0.8       , 0.0952381 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, comment level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *word2vec* features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec features, comments\n",
      "SVM accuracy:  0.6648873497333014\n",
      "Logistic regression accuracy:  0.7066117347344956\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *word2vec* + tf-idf features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec + tf-idf features, comments\n",
      "SVM accuracy:  0.6961866093463897\n",
      "Logistic regression accuracy:  0.7097762916965209\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec + tf-idf features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_train_test_features(language=\"cat\",tf_idf=False,full_comments=False,k=1):\n",
    "    if full_comments:\n",
    "        train,test = get_train_test.get_train_test_comments(k=k,language=language)\n",
    "    else:\n",
    "        train,test = get_train_test.get_train_test(k=k,language=language)\n",
    "    #train,test = get_train_test.get_train_test(k,lemmatize=True,language=language)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        vect = w2v_ca(sentence[0])\n",
    "        if not np.isnan(np.sum(vect)): ## check that it is not nan\n",
    "            X_train.append(vect)\n",
    "            y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        vect = w2v_ca(sentence[0])\n",
    "        if not np.isnan(np.sum(vect)): ## check that it is not nan\n",
    "            X_test.append(vect)\n",
    "            y_test.append(sentence[1])\n",
    "    if tf_idf == True:\n",
    "        transformer = TfidfTransformer(smooth_idf=False)\n",
    "        X_train = transformer.fit_transform(X_train).toarray()\n",
    "        X_test = transformer.transform(X_test).toarray()\n",
    "    return X_train,y_train,np.array(X_test),y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1200 instances, test on 398 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,tf_idf=True,full_comments=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec + tf-idf features, comments\n",
      "SVM accuracy:  0.6326633165829145\n",
      "Logistic regression accuracy:  0.6432160804020101\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec + tf-idf features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2193 instances, test on 729 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_w2v_train_test_features(k=i,tf_idf=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec features, comments\n",
      "SVM accuracy:  0.6509615384615385\n",
      "Logistic regression accuracy:  0.6552197802197802\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
