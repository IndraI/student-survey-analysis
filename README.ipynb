{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of student evaluation of teaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains code for work for dataset creation and sentiment polarity detection of textual answers from student surveys from University of Barcelona bachelor programs. \n",
    "\n",
    "The goals of this project are: \n",
    "\n",
    "1) to create a supervised dataset for sentiment analysis and polarity detection of student opinions in two languages (Catalan and Spanish);\n",
    "\n",
    "2) to validate the dataset empirically and propose competitive baselines by investigating, implementing and comparing sentiment analysis algorithms and methods to automatically classify student comments as positive, negative or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are listed scripts, notebooks and data, that are published in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for dataset creation and annoymization are in this repository. This includes:\n",
    "\n",
    "* *pdf* scraping\n",
    "* MongoDB creation\n",
    "* sentence segmentation\n",
    "* language detection\n",
    "* translation to English\n",
    "* annonymization\n",
    "\n",
    "The original dataset is not public, and the files that are in the *data* folder are already pre-processed and annoymized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment lexicons\n",
    "\n",
    "Downloaded from [kaggle](https://www.kaggle.com/rtatman/sentiment-lexicons-for-81-languages/data).\n",
    "\n",
    "Unsupervised method. Predicts setiment of sentences by counting how many positive and negative words each sentence has.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature vectors\n",
    "\n",
    "These are the types of feature vectors used in this work. These vectors are created from\n",
    "* tokenized sentences, \n",
    "* tokenized comments, \n",
    "* tokenezied English translations, \n",
    "* lemmatized sentences,\n",
    "* POS tags.\n",
    "\n",
    "All of these vectors are tested with and without TF-IDF.\n",
    "\n",
    "### bag-of-words\n",
    "\n",
    "Tokenize all training texts and create vocabulary. *bag-of-words* feature vector has the length of the vocabulary.\n",
    "\n",
    "* **BTO (binary term occurences)** - for every word in each sentence, put 0 for words that don't appear in that particular sentence an 1 for words that appear in that sentence.\n",
    "\n",
    "* **term frequencies** - similar to BTO but instead of 1 and 0 put counts of how many times each word appears in each sentence.\n",
    "\n",
    "### *n*-grams\n",
    "\n",
    "Creating n-gram features is similar to creating the bag-of-words features except that instead of taking one word, we take a sequence of *n* words.\n",
    "\n",
    "To create the vocabulary for n-grams we will create a list of all co-occurring words with a window of *n*.\n",
    "\n",
    "The length of each feature vector then will be the length of the vocabulary of *n-grams. \n",
    "\n",
    "### *word2vec* embeddings\n",
    "\n",
    "Neural networks that assign to each word a vector in n-dimensional vector space, such that words that appear in similar context will be be located closely in the vector space. \n",
    "\n",
    "To train these embeddings we download all texts from Spanish and Catalan *Wikipedia*.\n",
    "\n",
    "Pre-train word embeddings using *Gensim* *word2vec* with 100 dimensions.\n",
    "\n",
    "### TF-IDF weights\n",
    "\n",
    "This weight can be calculated for each word, *n*-gram, lemma and so on.\n",
    "\n",
    "TF term is used to normalize variation in sentence length (for longer sentences it is more likley that certain terms will appear more time).\n",
    "\n",
    "$$\n",
    "\\text{TF}(t) = \\frac{\\text{number of times term appears}}{\\text{total number of terms}} \n",
    "$$\n",
    "\n",
    "IDF term is used to decrease weights of terms that appear very often in all the training corpus (often stop-words, like, \"la\", \"y\", and so on).\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t) = \\log_{e}\\Big(\\frac{\\text{total number of sentences}}{\\text{number of sentences that contain this term}}\\Big)\n",
    "$$\n",
    "\n",
    "TF-IDF is combines both of these weights.\n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(t) = \\text{TF}(t) \\times \\text{IDF}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used ML models\n",
    "\n",
    "All models are implemented with *sklearn*.\n",
    "\n",
    "* support vector machines\n",
    "* mulitnomial Naive Bayes\n",
    "* logistic regression\n",
    "* simple feed forward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks (feature vector creation and model testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BOW and n-gram features on original Catalan and Spanish comments, English translations](original_texts_BOW_&_ngram_features.ipynb)\n",
    "\n",
    "[BOW features on lemmatized comments and POS tags](lemmatized_texts_&_POS_BOW_features.ipynb)\n",
    "\n",
    "[n-gram features on lemmatized comments and POS tags](lemmatized_texts_&_POS_ngram_features.ipynb)\n",
    "\n",
    "[word2vec features](word2vec_features.ipynb)\n",
    "\n",
    "[concatenated features](concatenated_features.ipynb)\n",
    "\n",
    "[simple feed forward neural network](feed_forward_neural_network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
