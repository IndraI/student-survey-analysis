{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW and *n*-gram feature extraction and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this nodebook are results from different bag-of-words and *n*-gram models and setups while working with the original sentences, comments, and their English translations. Both Catalan and Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, nltk, numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported file *get_train_test.py*. This file contains 3 functions:\n",
    "\n",
    "* **get_train_test(k=1,lemmatize=False,POS=False,language=\"es\")**\n",
    "\n",
    "Reads data from *txt* files. Returns two arrays of tuples (train and test), with sentences and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "*lemmatize* - if *True* returns word lemmas\n",
    "\n",
    "*POS* - if *True* reurns words in form \"*lemma_POStag*\"\n",
    "\n",
    "* **get_train_test_comments(k=1,language=\"es\")**\n",
    "\n",
    "Reads data from *MongoDB* (as sentence order in comments is saved there). Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "* **get_english_train_test(k=1,language=\"es\")**\n",
    "\n",
    "Reads data from pre-created *txt* files with sentences translated to English. Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "\n",
    "For all the functions train-test split is 3/4 to 1/4, selection order depending on parameter *k*.\n",
    "\n",
    "*k* - takes values 1 to 4 - changes the selection of train-test split (used for cross-validation).\n",
    "\n",
    "*language* - 'es' or 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(text,remove_stopwords=False,repeat=False):\n",
    "    if remove_stopwords == True:\n",
    "        #with open(\"data/es_stopwords.txt\") as f:\n",
    "        #    es_stopwords = f.readlines()\n",
    "        #es_stopwords = [x.strip() for x in es_stopwords] \n",
    "        with open(\"data/ca_stopwords.txt\") as f:\n",
    "            ca_stopwords = f.readlines()\n",
    "        ca_stopwords = [x.strip() for x in ca_stopwords] \n",
    "        es_stopwords = set(stopwords.words(\"spanish\"))\n",
    "        for stopword in es_stopwords:\n",
    "            text = re.sub(stopword, '', text)\n",
    "        for stopword in ca_stopwords:\n",
    "            text = re.sub(stopword, '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    punctuation = ['.',',','%','&','\\'','/','+','!']\n",
    "    rx = '[' + re.escape(''.join(punctuation)) + ']'\n",
    "    text = re.sub(rx, '', text)\n",
    "    if repeat:\n",
    "        tokens = nltk.wordpunct_tokenize(text)\n",
    "    else:\n",
    "        tokens = sorted(set(nltk.wordpunct_tokenize(text)))\n",
    "    remove_from_vocabulary = ['-',')','(','(?)','1','=','[',']','][',':','<','>',';',':)','?']\n",
    "    for i in remove_from_vocabulary:\n",
    "        if i in tokens:\n",
    "            tokens.remove(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = get_word_list(text,remove_stopwords=False,repeat=True)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to create BOW feature vectors. Parameters - sentence to convert and vocabulary.\n",
    "\n",
    "remove_stopwords - removes spanish stopwords (like, \"la\", \"el\", ...) (I downloaded this list from github)\n",
    "\n",
    "repeat - keeps all the instances of the same word (if False then only keeps distinct words). Use False if BOW vectors with only 1 and 0 are needed (word either appears or not), and True if BOW vectors with word frequencies are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW(sentence, vocabulary,remove_stopwords=False,repeat=False):\n",
    "    sentence_words = get_word_list(sentence,remove_stopwords,repeat)\n",
    "    bag = np.zeros(len(vocabulary))\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(vocabulary):\n",
    "            if word == w: \n",
    "                bag[i] += 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2grams_vocab(tokens):\n",
    "    bigr = list(bigrams(tokens))\n",
    "    fdist = nltk.FreqDist(bigr)\n",
    "    bi_grams = [x[0] for x in list(fdist.items()) if x[1] >= 1]\n",
    "    return bi_grams\n",
    "\n",
    "def get_3grams_vocab(tokens):\n",
    "    trigr = list(trigrams(tokens))\n",
    "    fdist = nltk.FreqDist(trigr)\n",
    "    tri_grams = [x[0] for x in list(fdist.items()) if x[1] >= 1]\n",
    "    return tri_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_to_features(sentence, ngramlist, n=2):\n",
    "    tokens = tokenize(sentence)\n",
    "    if n==3:\n",
    "        sentence_ngrams = list(trigrams(tokens))\n",
    "    elif n == 4 or n==5:\n",
    "        sentence_ngrams = list(ngrams(tokens, n))\n",
    "    else:\n",
    "        sentence_ngrams = list(bigrams(tokens))\n",
    "    bag = np.zeros(len(ngramlist))\n",
    "    for w in sentence_ngrams:\n",
    "        for i,word in enumerate(ngramlist):\n",
    "            if word == w: \n",
    "                bag[i] += 1\n",
    "                \n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates BOW feature vectores.\n",
    "\n",
    "tf_idf\n",
    "\n",
    "remove_stopwords - removes spanish stopwords (like, \"la\", \"el\", ...) (I downloaded this list from github)\n",
    "\n",
    "repeat - keeps all the instances of the same word (if False then only keeps distinct words). Use False if BOW vectors with only 1 and 0 are needed (word either appears or not), and True if BOW vectors with word frequencies are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BOW_train_test_features(language=\"es\",tf_idf=False,remove_stopwords=False,repeat=False,full_comments=False,english=False,k=1):\n",
    "    if full_comments:\n",
    "        train,test = get_train_test.get_train_test_comments(k=k,language=language)\n",
    "    elif english:\n",
    "        train,test = get_train_test.get_english_train_test(k=k,language=language)\n",
    "    else:\n",
    "        train,test = get_train_test.get_train_test(k=k,language=language)\n",
    "    train_corpus = \" \".join([i[0] for i in train])\n",
    "    vocabulary = get_word_list(train_corpus)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        bow = BOW(sentence[0],vocabulary,remove_stopwords,repeat)\n",
    "        X_train.append(bow)\n",
    "        y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        bow = BOW(sentence[0],vocabulary,remove_stopwords,repeat)\n",
    "        X_test.append(bow)\n",
    "        y_test.append(sentence[1])\n",
    "    if tf_idf == True:\n",
    "        transformer = TfidfTransformer(smooth_idf=False)\n",
    "        X_train = transformer.fit_transform(X_train).toarray()\n",
    "        X_test = transformer.transform(X_test).toarray() \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_train_test_features(language=\"es\",n=2,tf_idf=False,full_comments=False,english=False,k=1):\n",
    "    if full_comments:\n",
    "        train,test = get_train_test.get_train_test_comments(k,language=language)\n",
    "    elif english:\n",
    "        train,test = get_train_test.get_english_train_test(k,language=language)\n",
    "    else:\n",
    "        train,test = get_train_test.get_train_test(k,language=language)\n",
    "    train_corpus = \" \".join([i[0] for i in train])\n",
    "    tokens = tokenize(train_corpus)\n",
    "    if n==3:\n",
    "        ngramlist = get_3grams_vocab(tokens)\n",
    "    elif n > 3:\n",
    "        ngramlist = list(ngrams(tokens, n))\n",
    "    else:\n",
    "        ngramlist = get_2grams_vocab(tokens)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        f = ngrams_to_features(sentence[0],ngramlist,n)\n",
    "        X_train.append(f)\n",
    "        y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        f = ngrams_to_features(sentence[0],ngramlist,n)\n",
    "        X_test.append(f)\n",
    "        y_test.append(sentence[1])\n",
    "    if tf_idf == True:\n",
    "        transformer = TfidfTransformer()\n",
    "        X_train = transformer.fit_transform(X_train).toarray()\n",
    "        X_test = transformer.transform(X_test).toarray() \n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for Catalan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,2,3,4]\n",
    "random_states = [0,1,2,4,5,42,50,60,70,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, balanced class weights, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6470072659171813\n",
      "SVM precision:  0.6989130004629689\n",
      "SVM recall:  0.6721536351165981\n",
      "SVM F1:  0.6802387595681454\n",
      "SVM kappa:  0.4455391665473293\n",
      "------\n",
      "Multinomial NB accuracy:  0.6923389798066801\n",
      "Multinomial NB precision:  0.6735450136192391\n",
      "Multinomial NB recall:  0.6995884773662552\n",
      "Multinomial NB F1:  0.6426575719849508\n",
      "Multinomial NB kappa:  0.41216171434883453\n",
      "------\n",
      "Logistic regression accuracy:  0.6803700138300129\n",
      "Logistic regression precision:  0.702304647031837\n",
      "Logistic regression recall:  0.700960219478738\n",
      "Logistic regression F1:  0.7016125740405577\n",
      "Logistic regression kappa:  0.4923041536485786\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Multinomial NB precision: \", precision_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB recall: \", recall_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB F1: \", f1_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB kappa: \", cohen_kappa_score(y_test, predicted_nb))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59728507, 0.21719457, 0.18552036],\n",
       "       [0.05778894, 0.7839196 , 0.15829146],\n",
       "       [0.11818182, 0.46363636, 0.41818182]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60633484, 0.39366516, 0.        ],\n",
       "       [0.05276382, 0.93969849, 0.00753769],\n",
       "       [0.07272727, 0.90909091, 0.01818182]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7239819 , 0.16289593, 0.11312217],\n",
       "       [0.10552764, 0.77889447, 0.11557789],\n",
       "       [0.19090909, 0.43636364, 0.37272727]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, not balanced class weights, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features (not balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6776321591896401\n",
      "SVM precision:  0.6878437956000542\n",
      "SVM recall:  0.6941015089163237\n",
      "SVM F1:  0.6815270092714738\n",
      "SVM kappa:  0.44823337745647074\n",
      "------\n",
      "Logistic regression accuracy:  0.702950277632347\n",
      "Logistic regression precision:  0.6906909087256016\n",
      "Logistic regression recall:  0.7133058984910837\n",
      "Logistic regression F1:  0.6966524905032667\n",
      "Logistic regression kappa:  0.48899755501222497\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features (not balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59276018, 0.29864253, 0.10859729],\n",
       "       [0.05025126, 0.86934673, 0.08040201],\n",
       "       [0.10909091, 0.62727273, 0.26363636]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73303167, 0.21719457, 0.04977376],\n",
       "       [0.10050251, 0.83668342, 0.06281407],\n",
       "       [0.18181818, 0.59090909, 0.22727273]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features + remove stop-words, balanced class weights, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,remove_stopwords=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features + removed stop-words (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.43097622626426396\n",
      "SVM precision:  0.5498772242933014\n",
      "SVM recall:  0.5363511659807956\n",
      "SVM F1:  0.453590082566995\n",
      "SVM kappa:  0.11296628291249977\n",
      "------\n",
      "Multinomial NB accuracy:  0.548939855394737\n",
      "Multinomial NB precision:  0.526882335009907\n",
      "Multinomial NB recall:  0.5500685871056241\n",
      "Multinomial NB F1:  0.4016668492105644\n",
      "Multinomial NB kappa:  0.016012147998172743\n",
      "------\n",
      "Logistic regression accuracy:  0.5150614844463961\n",
      "Logistic regression precision:  0.5164098163825087\n",
      "Logistic regression recall:  0.5198902606310014\n",
      "Logistic regression F1:  0.5130385459908494\n",
      "Logistic regression kappa:  0.17836407021340306\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features + removed stop-words (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Multinomial NB precision: \", precision_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB recall: \", recall_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB F1: \", f1_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB kappa: \", cohen_kappa_score(y_test, predicted_nb))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05429864, 0.73303167, 0.21266968],\n",
       "       [0.01256281, 0.88442211, 0.10301508],\n",
       "       [0.01818182, 0.73636364, 0.24545455]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02714932, 0.97285068, 0.        ],\n",
       "       [0.00502513, 0.99246231, 0.00251256],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28054299, 0.47058824, 0.24886878],\n",
       "       [0.17336683, 0.6959799 , 0.13065327],\n",
       "       [0.19090909, 0.44545455, 0.36363636]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features + remove stop-words, not balanced class weights, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,remove_stopwords=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features + removed stop-words (not balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.5149675172968986\n",
      "SVM precision:  0.5175135792419744\n",
      "SVM recall:  0.5445816186556928\n",
      "SVM F1:  0.4099530636016058\n",
      "SVM kappa:  0.022192056431575402\n",
      "------\n",
      "Logistic regression accuracy:  0.5431155810012779\n",
      "Logistic regression precision:  0.4185298291933165\n",
      "Logistic regression recall:  0.5349794238683128\n",
      "Logistic regression F1:  0.42846376440353007\n",
      "Logistic regression kappa:  0.022869343455310998\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features + removed stop-words (not balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04524887, 0.9321267 , 0.02262443],\n",
       "       [0.00753769, 0.97236181, 0.0201005 ],\n",
       "       [0.00909091, 0.99090909, 0.        ]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11312217, 0.88687783, 0.        ],\n",
       "       [0.08040201, 0.91708543, 0.00251256],\n",
       "       [0.06363636, 0.93636364, 0.        ]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features (balanced class weights), sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6333852662512034\n",
      "SVM precision:  0.6768081910785957\n",
      "SVM recall:  0.663923182441701\n",
      "SVM F1:  0.6688930285315153\n",
      "SVM kappa:  0.4299215765131712\n",
      "------\n",
      "Multinomial NB accuracy:  0.6923389798066801\n",
      "Multinomial NB precision:  0.6702752893286386\n",
      "Multinomial NB recall:  0.6995884773662552\n",
      "Multinomial NB F1:  0.6432119815183186\n",
      "Multinomial NB kappa:  0.4148312679370595\n",
      "------\n",
      "Logistic regression accuracy:  0.6830966093011996\n",
      "Logistic regression precision:  0.6911070723769087\n",
      "Logistic regression recall:  0.6872427983539094\n",
      "Logistic regression F1:  0.6887806123257557\n",
      "Logistic regression kappa:  0.4732608881663387\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Multinomial NB precision: \", precision_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB recall: \", recall_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB F1: \", f1_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB kappa: \", cohen_kappa_score(y_test, predicted_nb))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63800905, 0.22624434, 0.13574661],\n",
       "       [0.08291457, 0.76130653, 0.15577889],\n",
       "       [0.16363636, 0.47272727, 0.36363636]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6199095 , 0.3800905 , 0.        ],\n",
       "       [0.06030151, 0.9321608 , 0.00753769],\n",
       "       [0.08181818, 0.9       , 0.01818182]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74208145, 0.16289593, 0.09502262],\n",
       "       [0.11557789, 0.74874372, 0.13567839],\n",
       "       [0.21818182, 0.42727273, 0.35454545]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features (not balanced class weights), sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features (not balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6701347253419503\n",
      "SVM precision:  0.6736103932440763\n",
      "SVM recall:  0.6872427983539094\n",
      "SVM F1:  0.6767494300073893\n",
      "SVM kappa:  0.44457699672183737\n",
      "------\n",
      "Logistic regression accuracy:  0.700218052576567\n",
      "Logistic regression precision:  0.6967306600429606\n",
      "Logistic regression recall:  0.7187928669410151\n",
      "Logistic regression F1:  0.7026499977633002\n",
      "Logistic regression kappa:  0.49985441913233797\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features (not balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64253394, 0.2760181 , 0.08144796],\n",
       "       [0.0879397 , 0.82663317, 0.08542714],\n",
       "       [0.15454545, 0.57272727, 0.27272727]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73755656, 0.2081448 , 0.05429864],\n",
       "       [0.09798995, 0.84170854, 0.06030151],\n",
       "       [0.2       , 0.56363636, 0.23636364]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + tf-idf features (balanced class weights), sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + tf_idf features (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6772585893386927\n",
      "SVM precision:  0.7006937572828149\n",
      "SVM recall:  0.700960219478738\n",
      "SVM F1:  0.6718919294068729\n",
      "SVM kappa:  0.43150574675638265\n",
      "------\n",
      "Multinomial NB accuracy:  0.6420212835828177\n",
      "Multinomial NB precision:  0.7614348559152432\n",
      "Multinomial NB recall:  0.635116598079561\n",
      "Multinomial NB F1:  0.5516376906221301\n",
      "Multinomial NB kappa:  0.23788525479284095\n",
      "------\n",
      "Logistic regression accuracy:  0.7063721268007633\n",
      "Logistic regression precision:  0.6999359333874701\n",
      "Logistic regression recall:  0.7160493827160493\n",
      "Logistic regression F1:  0.6981368229191002\n",
      "Logistic regression kappa:  0.4829521508968494\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + tf_idf features (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Multinomial NB precision: \", precision_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB recall: \", recall_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB F1: \", f1_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB kappa: \", cohen_kappa_score(y_test, predicted_nb))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54751131, 0.40723982, 0.04524887],\n",
       "       [0.02512563, 0.92964824, 0.04522613],\n",
       "       [0.06363636, 0.75454545, 0.18181818]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29864253, 0.70135747, 0.        ],\n",
       "       [0.00753769, 0.99246231, 0.        ],\n",
       "       [0.01818182, 0.96363636, 0.01818182]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66515837, 0.29411765, 0.04072398],\n",
       "       [0.06532663, 0.87437186, 0.06030151],\n",
       "       [0.13636364, 0.61818182, 0.24545455]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + tf-idf features (not balanced class weights), sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + tf_idf features (not balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.7068168170704017\n",
      "SVM precision:  0.7795037297888661\n",
      "SVM recall:  0.6954732510288066\n",
      "SVM F1:  0.6440544381272382\n",
      "SVM kappa:  0.38898390512974435\n",
      "------\n",
      "Logistic regression accuracy:  0.7091137344975313\n",
      "Logistic regression precision:  0.7585030124334202\n",
      "Logistic regression recall:  0.7242798353909465\n",
      "Logistic regression F1:  0.6837755838680968\n",
      "Logistic regression kappa:  0.467726643636324\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + tf_idf features (not balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45701357, 0.54298643, 0.        ],\n",
       "       [0.01256281, 0.98743719, 0.        ],\n",
       "       [0.05454545, 0.82727273, 0.11818182]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6199095 , 0.3800905 , 0.        ],\n",
       "       [0.04773869, 0.94723618, 0.00502513],\n",
       "       [0.09090909, 0.78181818, 0.12727273]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + tf-idf features (balanced class weights), sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6734281261552377\n",
      "SVM precision:  0.6780474066566856\n",
      "SVM recall:  0.6858710562414266\n",
      "SVM F1:  0.6625377420511425\n",
      "SVM kappa:  0.4148272779851727\n",
      "------\n",
      "Multinomial NB accuracy:  0.6399692999986865\n",
      "Multinomial NB precision:  0.7614348559152432\n",
      "Multinomial NB recall:  0.635116598079561\n",
      "Multinomial NB F1:  0.5516376906221301\n",
      "Multinomial NB kappa:  0.23788525479284095\n",
      "------\n",
      "Logistic regression accuracy:  0.7070589361211036\n",
      "Logistic regression precision:  0.7004895588321132\n",
      "Logistic regression recall:  0.720164609053498\n",
      "Logistic regression F1:  0.7030367435862461\n",
      "Logistic regression kappa:  0.49469950256870265\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Multinomial NB precision: \", precision_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB recall: \", recall_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB F1: \", f1_score(y_test, predicted_nb, average='weighted'))\n",
    "print(\"Multinomial NB kappa: \", cohen_kappa_score(y_test, predicted_nb))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53846154, 0.3800905 , 0.08144796],\n",
       "       [0.04522613, 0.89949749, 0.05527638],\n",
       "       [0.08181818, 0.70909091, 0.20909091]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29864253, 0.70135747, 0.        ],\n",
       "       [0.00753769, 0.99246231, 0.        ],\n",
       "       [0.01818182, 0.96363636, 0.01818182]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69230769, 0.25791855, 0.04977376],\n",
       "       [0.06532663, 0.86934673, 0.06532663],\n",
       "       [0.16363636, 0.6       , 0.23636364]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + tf-idf features (not balanced class weights), sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features (not balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.7029135445928778\n",
      "SVM precision:  0.7704666782231113\n",
      "SVM recall:  0.6872427983539094\n",
      "SVM F1:  0.6341748322252306\n",
      "SVM kappa:  0.37120936989286357\n",
      "------\n",
      "Logistic regression accuracy:  0.7073971803287302\n",
      "Logistic regression precision:  0.7411210027120291\n",
      "Logistic regression recall:  0.7146776406035665\n",
      "Logistic regression F1:  0.6742361921387212\n",
      "Logistic regression kappa:  0.4497654013215907\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features (not balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43438914, 0.56561086, 0.        ],\n",
       "       [0.01507538, 0.98492462, 0.        ],\n",
       "       [0.06363636, 0.81818182, 0.11818182]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60180995, 0.39366516, 0.00452489],\n",
       "       [0.05527638, 0.93969849, 0.00502513],\n",
       "       [0.1       , 0.77272727, 0.12727273]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=2)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams, sentences\n",
      "------\n",
      "SVM accuracy:  0.6246482917025553\n",
      "SVM precision:  0.6690478941419349\n",
      "SVM recall:  0.6310013717421125\n",
      "SVM F1:  0.6449321594603259\n",
      "SVM kappa:  0.3943798988270609\n",
      "------\n",
      "Logistic regression accuracy:  0.6451152094486948\n",
      "Logistic regression precision:  0.6612941032655779\n",
      "Logistic regression recall:  0.6584362139917695\n",
      "Logistic regression F1:  0.6598142649168305\n",
      "Logistic regression kappa:  0.42137877614252517\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams + TF-IDF, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams + tf-idf, sentences\n",
      "------\n",
      "SVM accuracy:  0.5969569280482794\n",
      "SVM precision:  0.6479739255215056\n",
      "SVM recall:  0.6310013717421125\n",
      "SVM F1:  0.5550990998218441\n",
      "SVM kappa:  0.24162934775042344\n",
      "------\n",
      "Logistic regression accuracy:  0.6663368668359295\n",
      "Logistic regression precision:  0.6705187770955745\n",
      "Logistic regression recall:  0.6844993141289437\n",
      "Logistic regression F1:  0.6295228774025692\n",
      "Logistic regression kappa:  0.3833916218929623\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams + tf-idf, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=3)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigrams, sentences\n",
      "------\n",
      "SVM accuracy:  0.5563049940044924\n",
      "SVM precision:  0.5630427463598949\n",
      "SVM recall:  0.5665294924554184\n",
      "SVM F1:  0.5308880665299017\n",
      "SVM kappa:  0.18347989749369975\n",
      "------\n",
      "Logistic regression accuracy:  0.5937799658096562\n",
      "Logistic regression precision:  0.5559731822876984\n",
      "Logistic regression recall:  0.6063100137174211\n",
      "Logistic regression F1:  0.5533165190048753\n",
      "Logistic regression kappa:  0.23178348369188062\n"
     ]
    }
   ],
   "source": [
    "print(\"trigrams, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams + TF-IDF, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=3,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigrams + tf-idf, sentences\n",
      "------\n",
      "SVM accuracy:  0.4754867245012657\n",
      "SVM precision:  0.5699352785122451\n",
      "SVM recall:  0.5829903978052127\n",
      "SVM F1:  0.4791438769582689\n",
      "SVM kappa:  0.11968062920812716\n",
      "------\n",
      "Logistic regression accuracy:  0.590015181113119\n",
      "Logistic regression precision:  0.5624802654788682\n",
      "Logistic regression recall:  0.6021947873799726\n",
      "Logistic regression F1:  0.5170534036286406\n",
      "Logistic regression kappa:  0.17855644146034422\n"
     ]
    }
   ],
   "source": [
    "print(\"trigrams + tf-idf, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-grams, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=4)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-grams, sentences\n",
      "------\n",
      "SVM accuracy:  0.516495386555426\n",
      "SVM precision:  0.5492522787116231\n",
      "SVM recall:  0.5610425240054869\n",
      "SVM F1:  0.46395029135102156\n",
      "SVM kappa:  0.09134463699358486\n",
      "------\n",
      "Logistic regression accuracy:  0.5681048378773463\n",
      "Logistic regression precision:  0.5265652906256473\n",
      "Logistic regression recall:  0.5692729766803841\n",
      "Logistic regression F1:  0.47960519945618607\n",
      "Logistic regression kappa:  0.10958888123884092\n"
     ]
    }
   ],
   "source": [
    "print(\"4-grams, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-grams + TF-IDF, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=4,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-grams + tf-idf, sentences\n",
      "------\n",
      "SVM accuracy:  0.4123323087489374\n",
      "SVM precision:  0.6362937707966947\n",
      "SVM recall:  0.5679012345679012\n",
      "SVM F1:  0.4413778505642243\n",
      "SVM kappa:  0.06909006883467506\n",
      "------\n",
      "Logistic regression accuracy:  0.559550214956305\n",
      "Logistic regression precision:  0.5315398352742676\n",
      "Logistic regression recall:  0.5624142661179699\n",
      "Logistic regression F1:  0.44945088320409204\n",
      "Logistic regression kappa:  0.06936790923824976\n"
     ]
    }
   ],
   "source": [
    "print(\"4-grams + tf-idf, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, comment level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,language=\"cat\",full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features, comments\n",
      "SVM accuracy:  0.6227525125628142\n",
      "Logistic regression accuracy:  0.6614698492462311\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68382353, 0.16176471, 0.15441176],\n",
       "       [0.16666667, 0.703125  , 0.13020833],\n",
       "       [0.31428571, 0.28571429, 0.4       ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['POSITIVE', 'NEGATIVE','NEUTRAL'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72794118, 0.125     , 0.14705882],\n",
       "       [0.16145833, 0.71354167, 0.125     ],\n",
       "       [0.25714286, 0.27142857, 0.47142857]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['POSITIVE', 'NEGATIVE','NEUTRAL'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,language=\"cat\",repeat=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features, comments\n",
      "SVM accuracy:  0.6067126256281408\n",
      "Logistic regression accuracy:  0.6439667085427135\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + tf-idf features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,language=\"cat\",tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + tf_idf features, comments\n",
      "SVM accuracy:  0.6536774497487438\n",
      "Logistic regression accuracy:  0.6821419597989948\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + tf_idf features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + tf-idf features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,language=\"cat\",repeat=True,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features, comments\n",
      "SVM accuracy:  0.651169283919598\n",
      "Logistic regression accuracy:  0.671485552763819\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=2,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram features, comments\n",
      "SVM accuracy:  0.608953203517588\n",
      "Logistic regression accuracy:  0.6132600502512563\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams TF-IDF, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram + tf-idf features, comments\n",
      "SVM accuracy:  0.6088872487437185\n",
      "Logistic regression accuracy:  0.6420760050251257\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram + tf-idf features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, English translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2182 instances, test on 729 instances\n",
      "train on 2184 instances, test on 727 instances\n",
      "train on 2183 instances, test on 728 instances\n",
      "train on 2184 instances, test on 727 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,english=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features, English\n",
      "SVM accuracy:  0.6441682370659643\n",
      "Logistic regression accuracy:  0.6794815033451398\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2182 instances, test on 729 instances\n",
      "train on 2184 instances, test on 727 instances\n",
      "train on 2183 instances, test on 728 instances\n",
      "train on 2184 instances, test on 727 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,repeat=True,english=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features, English\n",
      "SVM accuracy:  0.6425967971422517\n",
      "Logistic regression accuracy:  0.6805117231253595\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + tf-idf features, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2182 instances, test on 729 instances\n",
      "train on 2184 instances, test on 727 instances\n",
      "train on 2183 instances, test on 728 instances\n",
      "train on 2184 instances, test on 727 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,tf_idf=True,english=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + tf_idf features, English\n",
      "SVM accuracy:  0.6917590931795476\n",
      "Logistic regression accuracy:  0.7052701086791997\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + tf_idf features, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + tf-idf features, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2182 instances, test on 729 instances\n",
      "train on 2184 instances, test on 727 instances\n",
      "train on 2183 instances, test on 728 instances\n",
      "train on 2184 instances, test on 727 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(k=i,repeat=True,tf_idf=True,english=True,language=\"cat\")\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features, English\n",
      "SVM accuracy:  0.692852885750613\n",
      "Logistic regression accuracy:  0.7045795113976933\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",english=True,k=i,n=2,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams, English\n",
      "SVM accuracy:  0.608953203517588\n",
      "Logistic regression accuracy:  0.6132600502512563\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams + TF-IDF, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1198 instances, test on 400 instances\n",
      "train on 1200 instances, test on 398 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"cat\",english=True,k=i,n=2,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams + tf-idf, English\n",
      "SVM accuracy:  0.6088872487437185\n",
      "Logistic regression accuracy:  0.6420760050251257\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams + tf-idf, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,2,3,4]\n",
    "random_states = [0,1,2,4,5,42,50,60,70,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features, sentences\n",
      "SVM accuracy:  0.6819768632268632\n",
      "Multinomial NB accuracy:  0.7428337428337428\n",
      "Logistic regression accuracy:  0.7301733551733551\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23809524, 0.61904762, 0.14285714],\n",
       "       [0.1       , 0.81818182, 0.08181818],\n",
       "       [0.05882353, 0.58823529, 0.35294118]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.02941176, 0.97058824, 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_nb,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07142857, 0.88095238, 0.04761905],\n",
       "       [0.03636364, 0.95454545, 0.00909091],\n",
       "       [0.05882353, 0.91176471, 0.02941176]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features + remove stop-words, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,remove_stopwords=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features, removed stopwords, sentences\n",
      "SVM accuracy:  0.7227537196287197\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7394638957138957\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features, removed stopwords, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features, sentences\n",
      "SVM accuracy:  0.6872002684502685\n",
      "Multinomial NB accuracy:  0.7428337428337428\n",
      "Logistic regression accuracy:  0.7335517335517335\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + tf-idf features, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + tf_idf features, sentences\n",
      "SVM accuracy:  0.7371721152971152\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7453589953589954\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + tf_idf features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + tf-idf features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,repeat=True,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features, sentenes\n",
      "SVM accuracy:  0.7393700518700519\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7470424970424969\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features, sentenes\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=2)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram features, sentences\n",
      "SVM accuracy:  0.6796267858767859\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7259958822458823\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams + TF-IDF, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=2,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram + tf_idf features, sentences\n",
      "SVM accuracy:  0.6870043338793338\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7470510283010283\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram + tf_idf features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=3)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram features, sentences\n",
      "SVM accuracy:  0.7160316566566567\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7470510283010283\n"
     ]
    }
   ],
   "source": [
    "print(\"trigram features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams + TF-IDF, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n",
      "train on 889 instances, test on 297 instances\n",
      "train on 890 instances, test on 296 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=3,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram + tf_idf features, sentences\n",
      "SVM accuracy:  0.6787196287196287\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.7478899353899354\n"
     ]
    }
   ],
   "source": [
    "print(\"trigram + tf_idf features, sentences\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish, comment level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTO features, comments\n",
      "SVM accuracy:  0.6503940003551897\n",
      "Multinomial NB accuracy:  0.7179399147544597\n",
      "Logistic regression accuracy:  0.6813247506016792\n"
     ]
    }
   ],
   "source": [
    "print(\"BTO features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,repeat=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features, comments\n",
      "SVM accuracy:  0.6384657104101217\n",
      "Multinomial NB accuracy:  0.7195122417984849\n",
      "Logistic regression accuracy:  0.6941655490437435\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + TF_IDF features, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO + TF-IDF features, comments\n",
      "SVM accuracy:  0.6910597438347019\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.7163373506518956\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO + TF-IDF features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW term frequency features + TF-IDF, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_nb = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,repeat=True,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5)\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_nb = clf_nb.predict(X_test)\n",
    "    results_nb.append(np.mean(predicted_nb == y_test))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5).fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + TF_IDF features, comments\n",
      "SVM accuracy:  0.6944069479402055\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.7179196291329083\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + TF_IDF features, comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=2,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram features, full comments\n",
      "SVM accuracy:  0.5889018129987201\n",
      "Multinomial NB accuracy:  0.7436754936754937\n",
      "Logistic regression accuracy:  0.6655517229764901\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram features, full comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams + TF-IDF, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=2,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram + tf-idf features, full comments\n",
      "SVM accuracy:  0.6731881877973949\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.7147550721708831\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram + tf-idf features, full comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=3,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram features, full comments\n",
      "SVM accuracy:  0.5379867018182041\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.6988710477485256\n"
     ]
    }
   ],
   "source": [
    "print(\"trigram features, full comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams + TF-IDF, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 472 instances, test on 159 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 473 instances, test on 158 instances\n",
      "train on 475 instances, test on 156 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=3,tf_idf=True,full_comments=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram + tf-idf features, full comments\n",
      "SVM accuracy:  0.6726462937786678\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.7115702295873063\n"
     ]
    }
   ],
   "source": [
    "print(\"trigram + tf-idf features, full comments\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English translations, Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW BTO features, English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 885 instances, test on 296 instances\n",
      "train on 886 instances, test on 295 instances\n",
      "train on 885 instances, test on 296 instances\n",
      "train on 887 instances, test on 294 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_BOW_train_test_features(language=\"es\",k=i,english=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features, English translations\n",
      "SVM accuracy:  0.6103026011137391\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.6425679570958022\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features, English translations\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams + TF-IDF, English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 885 instances, test on 296 instances\n",
      "train on 886 instances, test on 295 instances\n",
      "train on 885 instances, test on 296 instances\n",
      "train on 887 instances, test on 294 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_ngram_train_test_features(language=\"es\",k=i,n=1,tf_idf=True,english=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram + tf-idf features, English\n",
      "SVM accuracy:  0.701798389534467\n",
      "Multinomial NB accuracy:  0.7147550721708831\n",
      "Logistic regression accuracy:  0.7332438781742656\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram + tf-idf features, English\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"Multinomial NB accuracy: \", np.mean(results_nb))\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
