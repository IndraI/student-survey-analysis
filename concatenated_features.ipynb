{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook are tested models with concatenated best features.\n",
    "\n",
    "To not repeat, all the functions used for feature extraction are saved in \"feature_extraction.py\" which is imported. These functions are defined locally and explained more in other notebooks.\n",
    "\n",
    "Only Catalan dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_train_test\n",
    "import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,2,3,4]\n",
    "random_states = [0,1,2,4,5,42,50,60,70,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigrams TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigrams TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.710191895858439\n",
      "SVM precision:  0.7112871969296871\n",
      "SVM recall:  0.7308228730822873\n",
      "SVM F1:  0.711199209071092\n",
      "SVM kappa:  0.5095985172532329\n",
      "------\n",
      "Multinomial NB accuracy:  0.6528851889478975\n",
      "Multinomial NB precision:  0.7691434061676741\n",
      "Multinomial NB recall:  0.6596931659693166\n",
      "Multinomial NB F1:  0.5862900356871699\n",
      "Multinomial NB kappa:  0.29836410085705234\n",
      "------\n",
      "Logistic regression accuracy:  0.7221703906201549\n",
      "Logistic regression precision:  0.6944829900120596\n",
      "Logistic regression recall:  0.7168758716875872\n",
      "Logistic regression F1:  0.6965340129927217\n",
      "Logistic regression kappa:  0.48582541146048597\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigrams TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigrams POS TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True,POS=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigrams POS TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.68768428109856\n",
      "SVM precision:  0.704525756753175\n",
      "SVM recall:  0.7112970711297071\n",
      "SVM F1:  0.7044975125648788\n",
      "SVM kappa:  0.4898989551828431\n",
      "------\n",
      "Logistic regression accuracy:  0.7057298982170547\n",
      "Logistic regression precision:  0.7007298826488837\n",
      "Logistic regression recall:  0.7099023709902371\n",
      "Logistic regression F1:  0.7034218975115305\n",
      "Logistic regression kappa:  0.49084354131672747\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigrams POS TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + BOW frequences POS TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True,POS=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + BOW frequencies POS TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.6898489527526654\n",
      "SVM precision:  0.6991403218346467\n",
      "SVM recall:  0.704323570432357\n",
      "SVM F1:  0.6863726802336388\n",
      "SVM kappa:  0.4546335197815722\n",
      "------\n",
      "Logistic regression accuracy:  0.7123820820764839\n",
      "Logistic regression precision:  0.6900198343814615\n",
      "Logistic regression recall:  0.705718270571827\n",
      "Logistic regression F1:  0.692800998965621\n",
      "Logistic regression kappa:  0.4736854922315844\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + BOW frequencies POS TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + tri-grams TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=3,tf_idf=True,POS=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + tri-gram POS TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.6838952646491971\n",
      "SVM precision:  0.6991163447956431\n",
      "SVM recall:  0.698744769874477\n",
      "SVM F1:  0.6965245627136598\n",
      "SVM kappa:  0.47528408898405583\n",
      "------\n",
      "Logistic regression accuracy:  0.7036074321784824\n",
      "Logistic regression precision:  0.6980302803348265\n",
      "Logistic regression recall:  0.7140864714086471\n",
      "Logistic regression F1:  0.7021160946005418\n",
      "Logistic regression kappa:  0.490857006280071\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + tri-gram POS TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigram POS TF-IDF + bigram TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True,POS=True)\n",
    "    X_train3,y_train,X_test3,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2,X_train3),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2,X_test3),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigram POS TF-IDF + bigram TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.704768553275253\n",
      "SVM precision:  0.722252591853742\n",
      "SVM recall:  0.7336122733612274\n",
      "SVM F1:  0.7147004388910586\n",
      "SVM kappa:  0.5122257879533691\n",
      "------\n",
      "Logistic regression accuracy:  0.7193751878355448\n",
      "Logistic regression precision:  0.7091101963201413\n",
      "Logistic regression recall:  0.7224546722454672\n",
      "Logistic regression F1:  0.7112832997119448\n",
      "Logistic regression kappa:  0.5057981254805795\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigram POS TF-IDF + bigram TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    X_train3,y_train,X_test3,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=3,tf_idf=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2,X_train3),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2,X_test3),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.7148159636560675\n",
      "SVM precision:  0.707993166089176\n",
      "SVM recall:  0.7252440725244073\n",
      "SVM F1:  0.708158735673631\n",
      "SVM kappa:  0.5016335948966919\n",
      "------\n",
      "Logistic regression accuracy:  0.7260087254870371\n",
      "Logistic regression precision:  0.7069182938168294\n",
      "Logistic regression recall:  0.7252440725244073\n",
      "Logistic regression F1:  0.7014961998126128\n",
      "Logistic regression kappa:  0.494465023890052\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68663594, 0.25806452, 0.05529954],\n",
       "       [0.06632653, 0.87755102, 0.05612245],\n",
       "       [0.12962963, 0.62037037, 0.25      ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67281106, 0.28110599, 0.04608295],\n",
       "       [0.07397959, 0.89540816, 0.03061224],\n",
       "       [0.15740741, 0.62962963, 0.21296296]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams POS tagged TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    X_train3,y_train,X_test3,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=3,tf_idf=True)\n",
    "    X_train4,y_train,X_test4,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True,POS=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2,X_train3,X_train4),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2,X_test3,X_test4),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams POS tagd TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.7062724547195708\n",
      "SVM precision:  0.7226897137519892\n",
      "SVM recall:  0.7350069735006973\n",
      "SVM F1:  0.7189669960197933\n",
      "SVM kappa:  0.5194929333046456\n",
      "------\n",
      "Logistic regression accuracy:  0.7249784535680409\n",
      "Logistic regression precision:  0.708891736637406\n",
      "Logistic regression recall:  0.7238493723849372\n",
      "Logistic regression F1:  0.7088758019327636\n",
      "Logistic regression kappa:  0.5020623763626415\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams POS tagged TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + word2vec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/indra/anaconda/envs/icutestenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_w2v_train_test_features(k=i,language=\"cat\",tf_idf=True)\n",
    "    X_train=np.concatenate((X_train1,X_train2),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + word2vec TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.6838439824333049\n",
      "SVM precision:  0.6940465930618602\n",
      "SVM recall:  0.7071129707112971\n",
      "SVM F1:  0.6986186420131161\n",
      "SVM kappa:  0.48518148745862855\n",
      "------\n",
      "Logistic regression accuracy:  0.6987378171558034\n",
      "Logistic regression precision:  0.6871983353777521\n",
      "Logistic regression recall:  0.700139470013947\n",
      "Logistic regression F1:  0.692010952098867\n",
      "Logistic regression kappa:  0.47406399050172976\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + word2vec TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train1,y_train,X_test1,y_test = feature_extraction.get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True,tf_idf=True)\n",
    "    X_train2,y_train,X_test2,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2,tf_idf=True)\n",
    "    X_train3,y_train,X_test3,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=3,tf_idf=True)\n",
    "    X_train4,y_train,X_test4,y_test = feature_extraction.get_LP_ngram_train_test_features(language=\"cat\",k=i,n=2)\n",
    "    X_train=np.concatenate((X_train1,X_train2,X_train3,X_train4),axis=1)\n",
    "    X_test=np.concatenate((X_test1,X_test2,X_test3,X_test4),axis=1)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams, sentences\n",
      "------\n",
      "SVM accuracy:  0.6906925352246045\n",
      "SVM precision:  0.6855407701613135\n",
      "SVM recall:  0.701534170153417\n",
      "SVM F1:  0.6831046998544436\n",
      "SVM kappa:  0.45695659560010193\n",
      "------\n",
      "Logistic regression accuracy:  0.7036250536886096\n",
      "Logistic regression precision:  0.6859469823462988\n",
      "Logistic regression recall:  0.700139470013947\n",
      "Logistic regression F1:  0.6898210762477062\n",
      "Logistic regression kappa:  0.47150903873646255\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW frequencies TF-IDF + bigram TF-IDF + trigram TF-IDF + bigrams, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add sentiment words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TMF/sentiment-lexicons-kaggle/positive_words_es.txt\") as f:\n",
    "    pos_words = f.readlines()\n",
    "    pos_words = [x.strip() for x in pos_words] \n",
    "    \n",
    "with open(\"TMF/sentiment-lexicons-kaggle/negative_words_es.txt\") as f:\n",
    "    neg_words = f.readlines()\n",
    "    neg_words = [x.strip() for x in neg_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_words = np.concatenate((pos_words,neg_words),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_lexicon_features(sentence):\n",
    "    sentence_words = feature_extraction.get_word_list(sentence)\n",
    "    bag = np.zeros(len(sent_words))\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(sent_words):\n",
    "            if word == w: \n",
    "                bag[i] += 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_lexicon_train_test_features(tf_idf=False,k=1):\n",
    "    train,test = get_train_test.get_train_test(k,lemmatize=True,language=\"cat\")\n",
    "    train_corpus = \" \".join([i[0] for i in train])\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        X_train.append(sentiment_lexicon_features(sentence[0]))\n",
    "        y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        X_test.append(sentiment_lexicon_features(sentence[0]))\n",
    "        y_test.append(sentence[1])\n",
    "    #if tf_idf == True:\n",
    "    #    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    #    X_train = transformer.fit_transform(X_train).toarray()\n",
    "    #    X_test = transformer.transform(X_test).toarray() \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_sentiment_lexicon_train_test_features(k=i,tf_idf=True)\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment lexicon BOW TF-IDF, sentences\n",
      "------\n",
      "SVM accuracy:  0.5363144069384469\n",
      "SVM precision:  0.450047286375123\n",
      "SVM recall:  0.5439330543933054\n",
      "SVM F1:  0.43395080733621316\n",
      "SVM kappa:  0.035227553287795144\n",
      "------\n",
      "Logistic regression accuracy:  0.513891344665668\n",
      "Logistic regression precision:  0.4503577093727184\n",
      "Logistic regression recall:  0.5411436541143654\n",
      "Logistic regression F1:  0.43745930294483926\n",
      "Logistic regression kappa:  0.03686479777235219\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment lexicon BOW TF-IDF, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
