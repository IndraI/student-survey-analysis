{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW feature extraction and models, lemmatized texts, POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this nodebook are results from different bag-of-words models and setups while working with the lemmatized sentences and POS tags, only Catalan language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, nltk, numpy as np\n",
    "from nltk import bigrams, trigrams, ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported file *get_train_test.py*. This file contains 3 functions:\n",
    "\n",
    "* **get_train_test(k=1,lemmatize=False,POS=False,language=\"es\")**\n",
    "\n",
    "Reads data from *txt* files. Returns two arrays of tuples (train and test), with sentences and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "*lemmatize* - if *True* returns word lemmas\n",
    "\n",
    "*POS* - if *True* reurns words in form \"*lemma_POStag*\"\n",
    "\n",
    "* **get_train_test_comments(k=1,language=\"es\")**\n",
    "\n",
    "Reads data from *MongoDB* (as sentence order in comments is saved there). Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "* **get_english_train_test(k=1,language=\"es\")**\n",
    "\n",
    "Reads data from pre-created *txt* files with sentences translated to English. Returns two arrays of tuples (train and test), with comments and their labels ('pos','neg' or 'neu').\n",
    "\n",
    "\n",
    "For all the functions train-test split is 3/4 to 1/4, selection order depending on parameter *k*.\n",
    "\n",
    "*k* - takes values 1 to 4 - changes the selection of train-test split (used for cross-validation).\n",
    "\n",
    "*language* - 'es' or 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a list of words, with removed punctuation and numbers.\n",
    "\n",
    "*repeat* - returns all words, else only retuns the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(text,remove_stopwords=False,repeat=False):\n",
    "    if remove_stopwords == True:\n",
    "        #with open(\"/data/es_stopwords.txt\") as f:\n",
    "        #    es_stopwords = f.readlines()\n",
    "        #es_stopwords = [x.strip() for x in es_stopwords] \n",
    "        with open(\"/data/ca_stopwords.txt\") as f:\n",
    "            ca_stopwords = f.readlines()\n",
    "        ca_stopwords = [x.strip() for x in ca_stopwords] \n",
    "        es_stopwords = set(stopwords.words(\"spanish\"))\n",
    "        for stopword in es_stopwords:\n",
    "            text = re.sub(stopword, '', text)\n",
    "        for stopword in ca_stopwords:\n",
    "            text = re.sub(stopword, '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    punctuation = ['.',',','%','&','\\'','/','+','!']\n",
    "    rx = '[' + re.escape(''.join(punctuation)) + ']'\n",
    "    text = re.sub(rx, '', text)\n",
    "    if repeat:\n",
    "        tokens = nltk.wordpunct_tokenize(text)\n",
    "    else:\n",
    "        tokens = sorted(set(nltk.wordpunct_tokenize(text)))\n",
    "    remove_from_vocabulary = ['-',')','(','(?)','1','=','[',']','][',':','<','>',';',':)','?']\n",
    "    for i in remove_from_vocabulary:\n",
    "        if i in tokens:\n",
    "            tokens.remove(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to create BOW feature vectors. Parameters - sentence to convert and vocabulary.\n",
    "\n",
    "remove_stopwords - removes spanish stopwords (like, \"la\", \"el\", ...) (I downloaded this list from github)\n",
    "\n",
    "repeat - keeps all the instances of the same word (if False then only keeps distinct words). Use False if BOW vectors with only 1 and 0 are needed (word either appears or not), and True if BOW vectors with word frequencies are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW(sentence, vocabulary,remove_stopwords=False,repeat=False):\n",
    "    sentence_words = get_word_list(sentence,remove_stopwords,repeat)\n",
    "    bag = np.zeros(len(vocabulary))\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(vocabulary):\n",
    "            if word == w: \n",
    "                bag[i] += 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates feature vectors.\n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LP - lemmatized or POS tagges\n",
    "def get_LP_BOW_train_test_features(language=\"es\",POS=False,tf_idf=False,remove_stopwords=False,repeat=False,k=1):\n",
    "    if POS==True:\n",
    "        train,test = get_train_test.get_train_test(k,POS=True,language=language)\n",
    "    else:\n",
    "        train,test = get_train_test.get_train_test(k,lemmatize=True,language=language)\n",
    "    train_corpus = \" \".join([i[0] for i in train])\n",
    "    vocabulary = get_word_list(train_corpus)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sentence in train:\n",
    "        bow = BOW(sentence[0],vocabulary,remove_stopwords,repeat)\n",
    "        X_train.append(bow)\n",
    "        y_train.append(sentence[1])\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for sentence in test:\n",
    "        bow = BOW(sentence[0],vocabulary,remove_stopwords,repeat)\n",
    "        X_test.append(bow)\n",
    "        y_test.append(sentence[1])\n",
    "    if tf_idf == True:\n",
    "        transformer = TfidfTransformer(smooth_idf=False)\n",
    "        X_train = transformer.fit_transform(X_train).toarray()\n",
    "        X_test = transformer.transform(X_test).toarray() \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for Catalan (lemmatized texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models, sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,2,3,4]\n",
    "random_states = [0,1,2,4,5,42,50,60,70,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features (balanced class weights), sentences\n",
      "------\n",
      "SVM accuracy:  0.6503919018502462\n",
      "SVM precision:  0.6719726103640418\n",
      "SVM recall:  0.6736401673640168\n",
      "SVM F1:  0.6720964742239768\n",
      "SVM kappa:  0.44725137875822807\n",
      "------\n",
      "Logistic regression accuracy:  0.6889259364472542\n",
      "Logistic regression precision:  0.6931593643519732\n",
      "Logistic regression recall:  0.694560669456067\n",
      "Logistic regression F1:  0.6937691149164187\n",
      "Logistic regression kappa:  0.476684196844568\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features (balanced class weights), sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74654378, 0.1797235 , 0.07373272],\n",
       "       [0.12755102, 0.7372449 , 0.13520408],\n",
       "       [0.25      , 0.4537037 , 0.2962963 ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71889401, 0.17511521, 0.10599078],\n",
       "       [0.0994898 , 0.78061224, 0.11989796],\n",
       "       [0.14814815, 0.51851852, 0.33333333]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features + remove stop-words, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,remove_stopwords=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "    \n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW BTO features + removed stop-words, sentences\n",
      "------\n",
      "SVM accuracy:  0.4682421652696003\n",
      "SVM precision:  0.4703038397363161\n",
      "SVM recall:  0.5216178521617852\n",
      "SVM F1:  0.46192110849664725\n",
      "SVM kappa:  0.09949689495576775\n",
      "------\n",
      "Logistic regression accuracy:  0.5265918402696115\n",
      "Logistic regression precision:  0.5343856906381905\n",
      "Logistic regression recall:  0.5369595536959554\n",
      "Logistic regression F1:  0.5247407506492933\n",
      "Logistic regression kappa:  0.1884107382733391\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW BTO features + removed stop-words, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0921659 , 0.75576037, 0.15207373],\n",
       "       [0.08418367, 0.81632653, 0.0994898 ],\n",
       "       [0.03703704, 0.64814815, 0.31481481]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29493088, 0.52534562, 0.1797235 ],\n",
       "       [0.14285714, 0.71683673, 0.14030612],\n",
       "       [0.06481481, 0.56481481, 0.37037037]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + TF-IDF features, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW + tf-idf features, sentences\n",
      "------\n",
      "SVM accuracy:  0.6973512004005623\n",
      "SVM precision:  0.6908587847840124\n",
      "SVM recall:  0.7126917712691772\n",
      "SVM F1:  0.6929284936806823\n",
      "SVM kappa:  0.4767257718810337\n",
      "------\n",
      "Logistic regression accuracy:  0.7113223202598765\n",
      "Logistic regression precision:  0.6870159480928991\n",
      "Logistic regression recall:  0.7071129707112971\n",
      "Logistic regression F1:  0.6926048580325866\n",
      "Logistic regression kappa:  0.47649858668177913\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW + tf-idf features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0921659 , 0.75576037, 0.15207373],\n",
       "       [0.08418367, 0.81632653, 0.0994898 ],\n",
       "       [0.03703704, 0.64814815, 0.31481481]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69585253, 0.23502304, 0.06912442],\n",
       "       [0.08163265, 0.84438776, 0.07397959],\n",
       "       [0.15740741, 0.61111111, 0.23148148]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency features, sentences\n",
      "------\n",
      "SVM accuracy:  0.6421400040090788\n",
      "SVM precision:  0.6877062812916511\n",
      "SVM recall:  0.6820083682008368\n",
      "SVM F1:  0.6846909038701812\n",
      "SVM kappa:  0.4609857989297267\n",
      "------\n",
      "Logistic regression accuracy:  0.6850659635840506\n",
      "Logistic regression precision:  0.6932451885562246\n",
      "Logistic regression recall:  0.6861924686192469\n",
      "Logistic regression F1:  0.6894942911121518\n",
      "Logistic regression kappa:  0.4705969218652578\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70506912, 0.19354839, 0.10138249],\n",
       "       [0.09693878, 0.75765306, 0.14540816],\n",
       "       [0.17592593, 0.46296296, 0.36111111]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7235023 , 0.17050691, 0.10599078],\n",
       "       [0.10714286, 0.75      , 0.14285714],\n",
       "       [0.14814815, 0.47222222, 0.37962963]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + TF_IDF features, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,repeat=True, tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW term frequency + tf-idf features, sentences\n",
      "------\n",
      "SVM accuracy:  0.6982999444399793\n",
      "SVM precision:  0.6870776709926885\n",
      "SVM recall:  0.705718270571827\n",
      "SVM F1:  0.6902652565861838\n",
      "SVM kappa:  0.47013704771277764\n",
      "------\n",
      "Logistic regression accuracy:  0.7116827813771831\n",
      "Logistic regression precision:  0.6868153824455833\n",
      "Logistic regression recall:  0.705718270571827\n",
      "Logistic regression F1:  0.6923557190599705\n",
      "Logistic regression kappa:  0.47555923777961895\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW term frequency + tf-idf features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65437788, 0.25806452, 0.0875576 ],\n",
       "       [0.07653061, 0.8622449 , 0.06122449],\n",
       "       [0.14814815, 0.61111111, 0.24074074]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69124424, 0.22580645, 0.08294931],\n",
       "       [0.08673469, 0.84183673, 0.07142857],\n",
       "       [0.14814815, 0.61111111, 0.24074074]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,POS=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags BOW BTO features, sentences\n",
      "------\n",
      "SVM accuracy:  0.49928289507337226\n",
      "SVM precision:  0.5103135154848756\n",
      "SVM recall:  0.5523012552301255\n",
      "SVM F1:  0.4885927486416796\n",
      "SVM kappa:  0.14152875222397532\n",
      "------\n",
      "Logistic regression accuracy:  0.5482662936108198\n",
      "Logistic regression precision:  0.5291048837350969\n",
      "Logistic regression recall:  0.5481171548117155\n",
      "Logistic regression F1:  0.5298447693676717\n",
      "Logistic regression kappa:  0.19890201974571275\n"
     ]
    }
   ],
   "source": [
    "print(\"POS tags BOW BTO features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11059908, 0.75576037, 0.13364055],\n",
       "       [0.07142857, 0.8622449 , 0.06632653],\n",
       "       [0.03703704, 0.64814815, 0.31481481]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26728111, 0.5483871 , 0.1843318 ],\n",
       "       [0.16071429, 0.74744898, 0.09183673],\n",
       "       [0.12037037, 0.49074074, 0.38888889]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,POS=True,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags BOW term frequency features, sentences\n",
      "------\n",
      "SVM accuracy:  0.46550760134415664\n",
      "SVM precision:  0.5301752261114877\n",
      "SVM recall:  0.4672245467224547\n",
      "SVM F1:  0.45191150859277746\n",
      "SVM kappa:  0.1568730664450293\n",
      "------\n",
      "Logistic regression accuracy:  0.5458335354951\n",
      "Logistic regression precision:  0.5541091414874991\n",
      "Logistic regression recall:  0.5550906555090656\n",
      "Logistic regression F1:  0.5525088019558462\n",
      "Logistic regression kappa:  0.24349077197856717\n"
     ]
    }
   ],
   "source": [
    "print(\"POS tags BOW term frequency features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0921659 , 0.39170507, 0.51612903],\n",
       "       [0.05102041, 0.64285714, 0.30612245],\n",
       "       [0.05555556, 0.36111111, 0.58333333]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.359447  , 0.43778802, 0.20276498],\n",
       "       [0.19642857, 0.69387755, 0.10969388],\n",
       "       [0.2037037 , 0.35185185, 0.44444444]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTO + TF-IDF features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,POS=True,tf_idf=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags BOW BTO + tf-idf features, sentences\n",
      "------\n",
      "SVM accuracy:  0.5175885599197395\n",
      "SVM precision:  0.5396906244694359\n",
      "SVM recall:  0.5634588563458857\n",
      "SVM F1:  0.4706302594563601\n",
      "SVM kappa:  0.13301423207083574\n",
      "------\n",
      "Logistic regression accuracy:  0.5643906091260575\n",
      "Logistic regression precision:  0.5364311763341733\n",
      "Logistic regression recall:  0.5606694560669456\n",
      "Logistic regression F1:  0.5322772070273003\n",
      "Logistic regression kappa:  0.19924340192588608\n"
     ]
    }
   ],
   "source": [
    "print(\"POS tags BOW BTO + tf-idf features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05069124, 0.83870968, 0.11059908],\n",
       "       [0.02295918, 0.92091837, 0.05612245],\n",
       "       [0.00925926, 0.69444444, 0.2962963 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23963134, 0.62211982, 0.13824885],\n",
       "       [0.13010204, 0.78826531, 0.08163265],\n",
       "       [0.09259259, 0.52777778, 0.37962963]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency + TF_IDF features, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2191 instances, test on 731 instances\n",
      "train on 2193 instances, test on 729 instances\n"
     ]
    }
   ],
   "source": [
    "results_svm = []\n",
    "results_lr = []\n",
    "for i in k:\n",
    "    X_train,y_train,X_test,y_test = get_LP_BOW_train_test_features(language=\"cat\",k=i,POS=True,tf_idf=True,repeat=True)\n",
    "    accuracies = []\n",
    "    for s in random_states:\n",
    "        clf_svm = SGDClassifier(loss='hinge', alpha=1e-3, penalty='l2', random_state=s, max_iter=5,class_weight=\"balanced\")\n",
    "        clf_svm.fit(X_train, y_train) \n",
    "        predicted_svm = clf_svm.predict(X_test)\n",
    "        accuracies.append(np.mean(predicted_svm == y_test))\n",
    "    results_svm.append(np.mean(accuracies))\n",
    "\n",
    "    clf_lr = LogisticRegression(max_iter=5,class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    predicted_lr = clf_lr.predict(X_test)\n",
    "    results_lr.append(np.mean(predicted_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags BOW term frequency + tf-idf features, sentences\n",
      "------\n",
      "SVM accuracy:  0.5277511570340341\n",
      "SVM precision:  0.5328267447263357\n",
      "SVM recall:  0.5578800557880056\n",
      "SVM F1:  0.4677253110438668\n",
      "SVM kappa:  0.12694650800113705\n",
      "------\n",
      "Logistic regression accuracy:  0.5738105881901232\n",
      "Logistic regression precision:  0.549465879035555\n",
      "Logistic regression recall:  0.5732217573221757\n",
      "Logistic regression F1:  0.5400341554671492\n",
      "Logistic regression kappa:  0.2099401158791947\n"
     ]
    }
   ],
   "source": [
    "print(\"POS tags BOW term frequency + tf-idf features, sentences\")\n",
    "print(\"------\")\n",
    "print(\"SVM accuracy: \", np.mean(results_svm))\n",
    "print(\"SVM precision: \", precision_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM recall: \", recall_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM F1: \", f1_score(y_test, predicted_svm, average='weighted'))\n",
    "print(\"SVM kappa: \", cohen_kappa_score(y_test, predicted_svm))\n",
    "print(\"------\")\n",
    "print(\"Logistic regression accuracy: \", np.mean(results_lr))\n",
    "print(\"Logistic regression precision: \", precision_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression recall: \", recall_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression F1: \", f1_score(y_test, predicted_lr, average='weighted'))\n",
    "print(\"Logistic regression kappa: \", cohen_kappa_score(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05529954, 0.81105991, 0.13364055],\n",
       "       [0.02806122, 0.91326531, 0.05867347],\n",
       "       [0.        , 0.72222222, 0.27777778]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_svm,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24423963, 0.63133641, 0.12442396],\n",
       "       [0.10459184, 0.82142857, 0.07397959],\n",
       "       [0.11111111, 0.55555556, 0.33333333]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y_test, predicted_lr,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
