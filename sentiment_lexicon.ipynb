{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use this as a baseline score that can be achieved without machine learning models by simply conting a number of positive and negative words in a sentence based on a predefined positive and negative word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read lemmatized sentences from Freeling files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = []\n",
    "for file in os.listdir(\"data/es_neg/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/es_neg/\", file))\n",
    "for file in os.listdir(\"data/es_pos/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/es_pos/\", file))\n",
    "for file in os.listdir(\"data/es_neu/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/es_neu/\", file))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for filename in fileids:\n",
    "    polarity = filename[3:6]\n",
    "    #text = open(filename,\"r\").read()\n",
    "    lemma_file=\"\".join(('data/ESP_tagged/analyzed_',filename[7:]))\n",
    "    lemma_file = re.sub('assignatures', 'assingatures', lemma_file)\n",
    "    if os.path.isfile(lemma_file):\n",
    "        try:\n",
    "            with open(lemma_file) as f:\n",
    "                content = f.readlines()\n",
    "        except:\n",
    "             with open(lemma_file,encoding='latin1') as f:\n",
    "                content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        lemmas = []\n",
    "        for line in content:\n",
    "            if len(line.split())>0 :\n",
    "                lemmas.append(line.split()[1])\n",
    "        lemmatized_text = \" \".join(lemmas)\n",
    "\n",
    "    X.append(lemmatized_text)\n",
    "    y.append(polarity)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read positive and negative words from files. These files are downloaded from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/positive_words_es.txt\") as f:\n",
    "    pos_words = f.readlines()\n",
    "    pos_words = [x.strip() for x in pos_words] \n",
    "    \n",
    "with open(\"data/negative_words_es.txt\") as f:\n",
    "    neg_words = f.readlines()\n",
    "    neg_words = [x.strip() for x in neg_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for sentence in X:\n",
    "    pos_score = 0\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if word in pos_words:\n",
    "            pos_score += 1\n",
    "        if word in neg_words:\n",
    "            pos_score -= 1\n",
    "    if pos_score > 0:\n",
    "        y_pred.append('pos')\n",
    "    elif pos_score < 0:\n",
    "        y_pred.append('neg')\n",
    "    else:\n",
    "        y_pred.append('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.asarray(y_pred)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4814502529510961"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = []\n",
    "for file in os.listdir(\"data/ca_neg/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/ca_neg/\", file))\n",
    "for file in os.listdir(\"data/ca_pos/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/ca_pos/\", file))\n",
    "for file in os.listdir(\"data/ca_neu/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        fileids.append(os.path.join(\"data/ca_neu/\", file))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for filename in fileids:\n",
    "    polarity = filename[3:6]\n",
    "    #text = open(filename,\"r\").read()\n",
    "    lemma_file=\"\".join(('data/CAT_tagged/analyzed_',filename[7:]))\n",
    "    lemma_file = re.sub('assignatures', 'assingatures', lemma_file)\n",
    "    if os.path.isfile(lemma_file):\n",
    "        try:\n",
    "            with open(lemma_file) as f:\n",
    "                content = f.readlines()\n",
    "        except:\n",
    "             with open(lemma_file,encoding='latin1') as f:\n",
    "                content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        lemmas = []\n",
    "        for line in content:\n",
    "            if len(line.split())>0 :\n",
    "                lemmas.append(line.split()[1])\n",
    "        lemmatized_text = \" \".join(lemmas)\n",
    "\n",
    "    X.append(lemmatized_text)\n",
    "    y.append(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/positive_words_ca.txt\") as f:\n",
    "    pos_words = f.readlines()\n",
    "    pos_words = [x.strip() for x in pos_words] \n",
    "    \n",
    "with open(\"data/negative_words_ca.txt\") as f:\n",
    "    neg_words = f.readlines()\n",
    "    neg_words = [x.strip() for x in neg_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for sentence in X:\n",
    "    pos_score = 0\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if word in pos_words:\n",
    "            pos_score += 1\n",
    "        if word in neg_words:\n",
    "            pos_score -= 1\n",
    "    if pos_score > 0:\n",
    "        y_pred.append('pos')\n",
    "    elif pos_score < 0:\n",
    "        y_pred.append('neg')\n",
    "    else:\n",
    "        y_pred.append('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.asarray(y_pred)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3990417522245038"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51785714, 0.24404762, 0.23809524],\n",
       "       [0.28231293, 0.48639456, 0.23129252],\n",
       "       [0.25735294, 0.33823529, 0.40441176]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(y, y_pred,['pos', 'neg','neu'])\n",
    "np.transpose( np.transpose(C) / C.astype(np.float).sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
